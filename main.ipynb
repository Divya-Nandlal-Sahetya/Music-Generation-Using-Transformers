{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLONING THE REQUIRED FILES\n",
    "1. Midi Neural Processor to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/asigalov61/midi-neural-processor\n",
    "!git clone https://github.com/asigalov61/MusicTransformer-Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTALLING THE REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mir_eval.display\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pretty_midi\n",
    "from midi2audio import FluidSynth\n",
    "from IPython.display import display, Javascript, HTML, Audio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Model:\n",
    "    <br>1. Preprocess the Maestro dataset\n",
    "    <br>2. Training the Music Transformer on the Maestro Dataset for 150 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./MusicTransformer-Pytorch/dataset/\n",
    "%cd ./dataset\n",
    "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
    "!unzip maestro-v2.0.0-midi.zip\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the Maestro Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./MusicTransformer-Pytorch/\n",
    "!python3 preprocess_midi.py './dataset/maestro-v2.0.0'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "number_of_training_epochs = 150\n",
    "maximum_output_MIDI_sequence = 1280\n",
    "\n",
    "!python3 train.py -output_dir rpr --rpr -batch_size=$batch_size -epochs=$number_of_training_epochs -max_sequence=$maximum_output_MIDI_sequence #-n_layers -num_heads -d_model -dim_feedforward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model\n",
    "<br>Best Resulting Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 evaluate.py -model_weights rpr/results/best_acc_weights.pickle --rpr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 evaluate.py -model_weights rpr/results/best_loss_weights.pickle --rpr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Custom MIDI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd MusicTransformer-Pytorch\n",
    "from processor import encode_midi\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "%cd './dataset/e_piano/custom_midis'\n",
    "\n",
    "custom_MIDI_DataSet_dir = './dataset/e_piano/custom_midis'\n",
    "\n",
    "train_dir = './dataset/e_piano/train' # split_type = 0\n",
    "test_dir = './dataset/e_piano/test' # split_type = 1  \n",
    "val_dir = './dataset/e_piano/val' # split_type = 2\n",
    "\n",
    "total_count = 0\n",
    "train_count = 0\n",
    "val_count   = 0\n",
    "test_count  = 0\n",
    "\n",
    "f_ext = '.pickle'\n",
    "fileList = os.listdir(custom_MIDI_DataSet_dir)\n",
    "print(fileList)\n",
    "for file in fileList:\n",
    "     # we gonna split by a random selection for now\n",
    "    \n",
    "    split = random.randint(1, 2)\n",
    "    if (split == 0):\n",
    "         o_file = os.path.join(train_dir, file+f_ext)\n",
    "         train_count += 1\n",
    "\n",
    "    elif (split == 2):\n",
    "         o_file0 = os.path.join(train_dir, file+f_ext)\n",
    "         train_count += 1\n",
    "         o_file = os.path.join(val_dir, file+f_ext)\n",
    "         val_count += 1\n",
    "\n",
    "    elif (split == 1):\n",
    "         o_file0 = os.path.join(train_dir, file+f_ext)\n",
    "         train_count += 1\n",
    "         o_file = os.path.join(test_dir, file+f_ext)\n",
    "         test_count += 1\n",
    "    try:\n",
    "      print(o_file0)\n",
    "      prepped = encode_midi(file)\n",
    "      o_stream = open(o_file0, \"wb\")\n",
    "      pickle.dump(prepped, o_stream)\n",
    "      o_stream.close()\n",
    "\n",
    "      prepped = encode_midi(file)\n",
    "      o_stream = open(o_file, \"wb\")\n",
    "      pickle.dump(prepped, o_stream)\n",
    "      o_stream.close()\n",
    "   \n",
    "      print(file)\n",
    "      print(o_file)\n",
    "      print('Coverted!')  \n",
    "    except KeyboardInterrupt: \n",
    "      raise   \n",
    "    except:\n",
    "      print('Bad file. Skipping...')\n",
    "\n",
    "print('Done')\n",
    "print(\"Num Train:\", train_count)\n",
    "print(\"Num Val:\", val_count)\n",
    "print(\"Num Test:\", test_count)\n",
    "print(\"Total Count:\", train_count)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model on our Custom Dataset\n",
    "<br> Using the checkpoint of 150 epochs of Base Model\n",
    "<br> Training for 50 more epochs on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "number_of_training_epochs = 200\n",
    "maximum_output_MIDI_sequence = 512\n",
    "saved_checkpoint_full_path = \"./rpr/weights/epoch_0150.pickle\" \n",
    "continue_epoch_number = 150\n",
    "!python3 train.py -output_dir rpr --rpr -batch_size=$batch_size -epochs=$number_of_training_epochs -max_sequence=$maximum_output_MIDI_sequence -continue_weights $saved_checkpoint_full_path -continue_epoch $continue_epoch_number"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 evaluate.py -model_weights rpr/results/best_acc_weights.pickle --rpr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (main, Sep 14 2022, 22:38:23) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
